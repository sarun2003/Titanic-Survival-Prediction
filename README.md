# Titanic Survival Prediction

## Project Overview
This project develops a machine learning model to predict the survival of passengers aboard the Titanic. The model is trained using a dataset containing details about the passengers, such as age, sex, ticket class, and survival status. The goal is to accurately predict survival outcomes based on these features, utilizing data preprocessing, exploratory data analysis, and machine learning algorithms.

## Data Source
The dataset used in this project was provided by Afame Technologies as part of an internship program. It contains passenger information from the Titanic disaster, including demographics, ticket details, and survival status.

## Installation
To set up this project locally, follow these steps:

1. Clone the repository:
   git clone https://github.com/sarun2003>/titanic-survival-prediction.git
   
2. Navigate to the project directory:
   cd titanic-survival-prediction

3. Install the required Python packages:
   pip install -r requirements.txt

## Usage
To run the project, execute the main script from the project's root directory:
python src/main.py

This script will load the data, preprocess it, train a machine learning model, and evaluate the model's performance. The output will display the accuracy of the model in predicting the survival of Titanic passengers.

## Structure
The project directory is organized as follows:

titanic-survival-prediction/
├── data/

│ └── Titanic-Dataset.csv # Dataset provided by Afame Technologies

├── notebooks/

│ └── Exploratory_Data_Analysis.ipynb # Jupyter notebook for data analysis

├── src/

│ ├── data_preprocessing.py # Script for data preprocessing

│ ├── model_training.py # Script for model training

│ ├── model_evaluation.py # Script for model evaluation

│ └── main.py # Main script to run the project

├── .gitignore

├── README.md

└── requirements.txt

## Contributions
This project is a personal endeavor by me, completed during my internship with Afame Technologies. As such, it is not open to external contributions at this time.

## Acknowledgements
Special thanks to Afame Technologies for providing the dataset and the opportunity to work on this interesting and educational project.

